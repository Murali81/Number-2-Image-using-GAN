{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmura\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kmura\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "# Deterministic output.\n",
    "# Tired of seeing the same results every time? Remove the line below.\n",
    "\n",
    "\n",
    "# np.random.seed(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The results are a little better when the dimensionality of the random vector is only 10.\n",
    "# The dimensionality has been left at 100 for consistency with other GAN implementations.\n",
    "inputDim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train[:, np.newaxis, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=inputDim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Reshape((128, 7, 7)))\n",
    "generator.add(UpSampling2D(size=(2, 2)))\n",
    "generator.add(Conv2D(64, kernel_size=(5, 5), padding='same'))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(UpSampling2D(size=(2, 2)))\n",
    "generator.add(Conv2D(1, kernel_size=(5, 5), padding='same', activation='tanh'))\n",
    "generator.compile(loss='mse', optimizer=adam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=(1, 28, 28), kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(inputDim + 1, activation='softmax'))\n",
    "discriminator.compile(loss='categorical_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "ganInput = Input(shape=(inputDim,))\n",
    "x = generator(ganInput)\n",
    "ganOutput = discriminator(x)\n",
    "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='categorical_crossentropy', optimizer=adam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "image_folder = 'images_numb_Gan_mse_sftmx_cc_cc'\n",
    "\n",
    "if not os.path.exists(image_folder):\n",
    "    os.mkdir(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "model_folder = 'model_numb_Gan_mse_sftmx_cc_cc'\n",
    "\n",
    "if not os.path.exists(model_folder):\n",
    "    os.mkdir(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dLosses = []\n",
    "gLosses = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss from each batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotLoss(epoch):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(dLosses, label='Discriminitive loss')\n",
    "    plt.plot(gLosses, label='Generative loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('{}/dcgan_loss_epoch_%d.png'.format(image_folder) % epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a wall of generated MNIST images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "#     noise = np.random.normal(0, 1, size=[examples, randomDim])\n",
    "    \n",
    "    \n",
    "#     pickup_batch = np.random.randint(0, X_test.shape[0], size=examples)\n",
    "    \n",
    "    pickup_batch = np.arange(0,examples) \n",
    "\n",
    "    our_input = to_categorical(y_test[pickup_batch],inputDim)\n",
    "    \n",
    "    generatedImages = generator.predict(our_input)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i, 0], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}/dcgan_generated_image_epoch_%d.png'.format(image_folder) % epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the generator and discriminator networks (and weights) for later use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveModels(epoch):\n",
    "    generator.save('{}/dcgan_generator_epoch_%d.h5'.format(model_folder) % epoch)\n",
    "    discriminator.save('{}/dcgan_discriminator_epoch_%d.h5'.format(model_folder) % epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epochs=1, batchSize=128):\n",
    "    batchCount = X_train.shape[0] // batchSize\n",
    "    print ('Epochs:', epochs)\n",
    "    print ('Batch size:', batchSize)\n",
    "    print ('Batches per epoch:', batchCount)\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "\n",
    "        for _ in range(batchCount):\n",
    "            # Get a random set of input noise and images\n",
    "\n",
    "            \n",
    "            \n",
    "            pickup_batch = np.random.randint(0, X_train.shape[0], size=batchSize)\n",
    "\n",
    "            our_input = to_categorical(y_train[pickup_batch],inputDim)\n",
    "            \n",
    "            \n",
    "            imageBatch = X_train[pickup_batch]\n",
    "\n",
    "            # Generate fake MNIST images\n",
    "            generatedImages = generator.predict(our_input)\n",
    "            X = np.concatenate([imageBatch, generatedImages])\n",
    "\n",
    "            # Labels for generated and real data\n",
    "#             yDis = np.zeros(2*batchSize)\n",
    "            \n",
    "            image_outputs = to_categorical(y_train[pickup_batch],inputDim+1)\n",
    "            gen_image_outputs = to_categorical([inputDim]*batchSize,inputDim+1)  # 10 means 11. 11 means fake.\n",
    "            yDis = np.vstack((image_outputs,gen_image_outputs))\n",
    "            \n",
    "            \n",
    "            \n",
    "#             # One-sided label smoothing\n",
    "#             yDis[:batchSize] = 0.9\n",
    "\n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            dloss = discriminator.train_on_batch(X, yDis)\n",
    "\n",
    "            # Train generator\n",
    "#             noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "            our_input = to_categorical(y_train[pickup_batch],inputDim)\n",
    "    \n",
    "            yGen = to_categorical(y_train[pickup_batch],inputDim+1)\n",
    "\n",
    "\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(our_input, yGen)\n",
    "\n",
    "        # Store loss of most recent batch from this epoch\n",
    "        dLosses.append(dloss)\n",
    "        gLosses.append(gloss)\n",
    "\n",
    "        if e == 1 or e % 3 == 0:\n",
    "            plotGeneratedImages(e)\n",
    "            saveModels(e)\n",
    "\n",
    "    # Plot losses from every epoch\n",
    "    plotLoss(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train(15, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     train(75, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmura\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\keras\\models.py:287: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "discriminator=load_model('{}/dcgan_discriminator_epoch_12.h5'.format(model_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# import matplotlib\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "generator=load_model('{}/dcgan_generator_epoch_9.h5'.format(model_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAABJCAYAAAAQYrzyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADClJREFUeJzt3WtoHNUbx/HvptncmprUbm23JGmT\nWptqSlMsWIrQWCx9oTQEKkGJURGLpVr6poqCCPGFVftGYrVGpKggFUQtbfAGXlAK1qCBJFpv9UpM\nTGJjkt0km905/xfrjMm/zWaz2ezOpr8PLHQ3OzOnz855ZubMOWc8xhhERMR9stJdABERuTQlaBER\nl1KCFhFxKSVoERGXUoIWEXEpJWgREZdSghYRcSklaBERl1KCFhFxqewUb8/NwxY9ad6+YjM9xSY2\nxWd6GR0bnUGLiLiUErSIiEspQYuIuJQStMglGGMwxmBZFuFwON3FkcuUErSIiEuluhdHUoyNjdHX\n1wdAXl4eFy5cAKC0tBRjDC+//DIAR44ccb5399138/zzz6enwJI258+fB8Dn83HFFVfEvdydd94J\nwMMPP8y11147L2VzG9Wr+EUiEQAsyyIYDPLnn38CUFJSwuLFiwHweJLQgcW+lEvRK2HBYNAEg0Ez\nMDBgtm7daoqKikxRUZHx+/0mPz/f5Ofnm9raWnPLLbeY7Oxsk52dbYh2sXFeO3fujLWJVMciabFJ\nVE9Pj+np6TFbtmwxgBPHQ4cOmVAoZEKhkP3VjIxNd3e389tv2bLFWJYV13Jff/218fv9xu/3m5GR\nkZm+nu7YqF6loV5FIhETiUTMhx9+aCorK5247du3zwwPD5vh4eF4VjNj+TPiDNqyLM6cOQPAd999\nx/nz5xkfHwdg165dbNiwAYDHHnsMYwz19fUAvPXWW1PW88knnzhHvkWLFqWq+K7S398PwMaNG+np\n6Znyt9HRUQCam5vZvHkzAPX19WRlZV5LWCQSYceOHc77b7/9FmNMzLOazs5OAO677z5KS0sBnLOh\nhUj1au7a2toYHBx0/t+PP/44hYWFSVt/5tU8EZHLhMeYlA60iXtj9hG5p6eHQCDAwYMHAVi9ejXn\nzp1z3tfW1l60rGVZACxbtozBwUHn88LCQuf9JY70C2LE05kzZ7j11lsBeOaZZ6iqqgLg5MmTHD9+\n/KKz5slycnIA2Lx5M6+++ioA69atw5OUxrQ5mXVsPvjgA2praxkbGwOi/4/vv/8+5jL5+fkArFmz\nhra2NiCuM+h0xwZUr2KZlwQ3MDAAwKZNm+jv78fv9wPw888/z2Y1M8bGtU0cdk4IBoMcO3aMjo4O\nAIaGhmhsbGT37t3TLmtfkjc0NPDcc88B0ZseLS0tC/oSrK2tjRtvvBH7oLt3717ncisUChGJRMjO\njv7ky5Yt46abbgLg2LFjWJbFkiVLgGjs7finPzcn5tChQ4RCIef9HXfcEfP7Tz31lJPMDx48uGCb\nNlSvksO+MdrX10dBQQEvvfTSvGxHTRwiIm4Vz53EJL7iFg6HTTgcNq2traaiosIUFxeb4uJi88AD\nD5ihoaGYy/b395v+/n5TVlZmPB6P8Xg8Zvfu3WZ8fDzWYhl7t9myLGNZllm+fPmUu+tZWVmmpqbG\n1NTUmJaWFtPe3m4GBwfN4OBg3D0a/pUxsenq6jJdXV1ODOzff2JiYtplzp49awoLC51eChkWG9Wr\neapX0wmFQsbr9Rqv12sAU1JSYgKBgAkEArNd1Yzld20Th33JVF5ezt9//+3cXfZ6vRgzfbPSH3/8\nwXXXXQdEL+cqKysBePvttzOyN0I8JiYmALj++uv56KOPKCgoAKC9vZ3Vq1ens2gpZYxh06ZNzvus\nrCxeeeUVAKdp51J27NjByMgIK1asADK3WSceqldzV19f79Q5gC+++MKpc8nm2gRtq6ys5MEHH+TF\nF18E4NNPP+X+++/n8OHDAPj9fo4ePQrAk08+SV9fn7Oj5eXlcddddwEs6J3ot99+A6I3ejZs2ODE\n6nJKzgCnT5+eMix7165dNDQ0zLjc4sWL8Xq9vPnmm/NZPFdRvZo9+ybpyZMnnc+qq6tZtWrVvG3z\n8omuiEiGcW03u8lCoRDXXHMNED1bnFzm3Nxc58i2aNEiCgoKnL+fOHGCnTt3AnFdtqb7ujbhHyIQ\nCADQ2trKqVOn2L9/PwBbt25NTskyJDZFRUUMDQ0573t7e7nqqqtmXM7v9xMMBjlw4AAATzzxxGzK\nlu7YgOpVLElLcHV1dQC88847zqCdEydOzGWVMwcvExI0RC+rAKfNbLLly5cDcPbsWcrKyhLtIpax\nO5I9Z8L+/ft5//33qaioAKJ9or1ebzLK5urY/P777wCUlZVN+TwQCMRsG7T3/YKCAsbHx5322a++\n+oqNGzfGW7Z0xwZUr2JJSoKzLMu5j+HxeJw26Dk28WRuP+j/Zx/NL+WNN94AogMMLkf2TtLX10cw\nGHSGLDc0NPDaa68B/w1CWYi++eabS35eXl7O2rVrAbj66qt55JFHCAaDAKxYsYIjR44AOP2f7fbr\nG264wfneQqd6FZ9t27Y5B/Q1a9akrO1dbdAiIi6VEU0cgUBg2glIsrOz6e3tBeDKK69MvGQZfClm\n/4a9vb00NTVx+vRpINr9rry8HIBHH33UGQKeAFfHxm4HvP3225OysdzcXOcMOo4zpXTHBlSvYplz\nghseHp4yVe3rr7+erH1t5tjE01k6ia9Zi0Qi5tlnn71oikP7lZuba5qbm01zc3Miq59sQXSoj0Qi\npru723R3d5vbbrvNmQZx5cqV5sKFC4mu1tWxsQfqTLePxPPKysoyeXl5Ji8vz4yOjmZSbFSv5rle\n1dXVGcDk5OSYnJyc2e4fscxYfjVxiIi4lGubOOxLzD179tDZ2enMwlZcXMzSpUudwRkej8cZAdbV\n1TWXET0ZcSlmjKG7uxuIdpMqLS29aJSc/ZueOnWKxsZGIBqnH374AZ/Pl0jZMiI2VVVVdHV1TfnM\n7sWSn5/P2rVr+emnn4DoJbzdPdGyLDo6Oli3bh0w6zvz6Y4NqF7FknCCGxkZAaK9WcbGxpxRqu3t\n7ckpWSb34rBHNL333nsUFRU5E8gfPXqUgYEBZ9atUCjEL7/8AkQnEo9n5Fgm83g8fP755wA89NBD\n1NXVOe1h1dXVWJblTBX69NNPO92nDhw4kGhyzhidnZ3Oo5iys7NZunTpRd+xK11jYyOfffYZACtX\nrmT9+vWpK2gaqV7Fb+/evcB/XRAnjyBMmXjaQZL4itv27dvN9u3bjcfjMffcc48ZGBgwAwMDJhwO\nmx9//PGS7WaHDx+efSvQfzKmrcx+pE5+fr7xeDxT2lGzsrKmTBTk8/mMz+eL9xE808mY2MxkdHTU\njI6OGp/P50x4U11dPZdVpjs2qlfzsO+Mjo469yQAs2TJkkRXFcuM5VcbtIiIS7m2iWNym5fP53NG\ni7W2tnLvvfdecpmamppUFC3t7K5RwWAQy7KcSW2ampoYHBx0Bh8YYygpKQEW9rP1ZuPLL78E/ns2\nIyS1TdH1VK/i8+677zoDmABnaHuqufYmod3+c/z4cSorK/n111+BaJ/E6YTD4bk82SFjb2ZMFgqF\nnMdcVVRUONNt2jd8ErRgYmMf3CZPFwnRRxgl2N833bEB1atYEtp31q9fP+URaR0dHU69SqIZY6Mm\nDhERl3LtGbQ9Gm7Pnj1MTEzEnDPAPiuKdRYQh4w80qfIgohNKBRyRoT9/+RAubm5Uy5pZyHdsQHV\nq1hmve9EIhFWrVrFX3/9BUTnsRkZGUnWxGOTZW43u+rqauffsXYigH/++We+iyMLgNfrZdu2bQB8\n/PHHU/4WCoWcLnjTDX9eCFSvZmZZFvX19bzwwgtANGaxnsgzn1x7Bm1raWlh3759F+1MxcXFwH9T\nbSZBxh3pU2hBxMYYw7lz54DoU77tQStVVVU0NTVx8803J7LadMcGVK9imXVsjDGMj487Ty6vr6+n\ntLQ06QVDbdAiIpnL9WfQzoL/ltOyrLncUY4l4470KaTYTC/dsQHVq1gyet/JmASdAtqRpqfYTC/d\nsQHFJ5aMjo2aOEREXMq1vThEksm+Upzl8/TkMmY/Ai0cDuP1euerCSimVDdxiIhInNTEISLiUkrQ\nIiIupQQtIuJSStAiIi6lBC0i4lJK0CIiLqUELSLiUkrQIiIupQQtIuJSStAiIi6lBC0i4lJK0CIi\nLqUELSLiUkrQIiIupQQtIuJSStAiIi6lBC0i4lJK0CIiLqUELSLiUkrQIiIupQQtIuJSStAiIi6l\nBC0i4lL/A/uLRLrOT5WTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generatedImages = generator.predict(to_categorical(np.array([8,5,4,8,1]),inputDim))\n",
    "dim=(28,28)\n",
    "\n",
    "# plt.imshow(generatedImages[0, 0], interpolation='nearest', cmap='gray_r')\n",
    "## To plot ###\n",
    "dim=(10, 10)\n",
    "figsize=(10, 10)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "for i in range(generatedImages.shape[0]):\n",
    "    plt.subplot(dim[0], dim[1], i+1)\n",
    "    plt.imshow(generatedImages[i, 0], interpolation='nearest', cmap='gray_r')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generatedImages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
